{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Fachhochschule_Südwestfalen_20xx_logo.svg/320px-Fachhochschule_Südwestfalen_20xx_logo.svg.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Skriptsprachen\n",
    "### Sommersemester 2021\n",
    "Prof. Dr. Heiner Giefers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprache von Texten erkennen\n",
    "\n",
    "In dieser Aufgabe wollen wir uns mit dem Problem beschäftigen, die Sprache zu bestimmen, in der ein gewisser Text verfasst ist.\n",
    "Es gibt verschiedenste Ansätze, dieses Problem zu lösen.\n",
    "Wir werden ein sehr einfaches, Daten-getriebenes Verfahren einsetzen, bei dem die charakteristische *Buchstabenhäufigkeit* einer Sprache verwendet wird.\n",
    "\n",
    "Die Idee ist folgende: In den verschiedenen Sprachen kommen bestimmte Buchstaben - jedenfalls gefühlt - unterschiedlich häufig vor.\n",
    "Im Englischen, zum Beispiel, ist das *y* deutlich häufige als vor als im Deutschen, im Französischen ist das *e* (ohne Akzent) warscheinlich seltener als in anderen Sprachen.\n",
    "Versuchen wir also herauszufinden, ob diese Idee funktioniert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die mittleren Buschstabenhäufigkeiten in den verschiedenen Sprachen zu ermitteln, brauchen wir zunächst einmal **Daten**.\n",
    "Eine recht gute Quelle für Texte in verschiedenen Sprachen, ist [Wikipedia](https://www.wikipedia.org).\n",
    "Von dort werden wir verschiedene, zufällige Seiten in den unterschiedlichen Sprachen aufrufen und den Textinhalt dieser Seiten herunterladen.\n",
    "Für den Zugriff auf Wikipedia Seiten empfliehlt sich die Installation des Python-Pakets *Wikipedia-API*.\n",
    "Falls nicht vorhanden, installieren wir dieses Paket direkt aus dem Notebook heraus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_4FRptYMGtde",
    "outputId": "25af9d89-2421-4abe-979d-f1fd52f7df43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia-api in /opt/tljh/user/lib/python3.7/site-packages (0.5.4)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.7/site-packages (from wikipedia-api) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/tljh/user/lib/python3.7/site-packages (from requests->wikipedia-api) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/tljh/user/lib/python3.7/site-packages (from requests->wikipedia-api) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.7/site-packages (from requests->wikipedia-api) (2020.12.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/tljh/user/lib/python3.7/site-packages (from requests->wikipedia-api) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der nächsten Code-Zelle werden die Methoden `random_page` und `random_text` implementiert.\n",
    "`random_text(size,lang)` liefert einen Text mit `size` Zeichen in der Sprache `lang`.\n",
    "Um zufällige Wikipedia-Seiten herunterzuladen wir die Methode `random_page` verwendet.\n",
    "Wikipedia bietet über die URL [wikipedia.org/wiki/Special:Random](http://wikipedia.org/wiki/Special:Random) die Möglichkeit, eine zufällige Seite auszuwählen.\n",
    "Über diese URL holen wir uns den Titel der zufälligen Seite und laden den Inhalt schließlich mit der Wikipedia-API herunter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktglnRFmG2j2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import wikipediaapi\n",
    "\n",
    "def random_page(wiki, lang=\"de\"): \n",
    "  r = requests.get(\"https://\" + lang + \".wikipedia.org/wiki/Special:Random\")\n",
    "  soup = BeautifulSoup(r.content)\n",
    "  # Schneitet 12 Buchstaben vom Ende ab\n",
    "  # Funktioniert nicht bei allen Sprachen\n",
    "  #page = wiki.page(soup.title.text[:-12])\n",
    "  # Such nach \"Wikip\" im Titel\n",
    "  # Nimm den vorderen Teil ohne \" - \" (3 Buchstaben)\n",
    "  title = soup.title.text.split('Wikip')[0]\n",
    "  page = wiki.page(title[:-3])\n",
    "  assert page.exists(), f\"Die Seite {page} in {lang} ibt es nicht\"\n",
    "  return page.text\n",
    "\n",
    "def random_text(size,lang=\"de\"): \n",
    "  WIKI = wikipediaapi.Wikipedia(\n",
    "        language=lang,\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    "  )\n",
    "\n",
    "  text = ''\n",
    "  while(len(text)<size):\n",
    "    t = random_page(WIKI, lang)\n",
    "    t_cleaned = re.sub('[^a-zA-Z ]', '', t)\n",
    "    #Alles zu Kleinbuchstaben\n",
    "    t_cleaned = t_cleaned.lower()\n",
    "    text += t_cleaned\n",
    "\n",
    "  return text[:size]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Verwenden Sie die Funktion `random_text` um einen Englischen Text mit 200 Zeichen zu erzeugen. Teilen Sie den Text in einzelne Worte auf, die in der Liste `worte` abgelegt sind. Die `for`-Schleife durchläuft diese Liste und gibt die einzelnen Worte aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "abde7639efb50e6ba7cbc320787582d5",
     "grade": true,
     "grade_id": "cell-8fa64d14f16a94a3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "worte = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "for i, wort in enumerate(worte):\n",
    "    print(f\"{i}) {wort}\", end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Als nächstes wollen wir die Häufigkeiten der Buchstaben im Text bestimmen.\n",
    "Dazu verwenden wir ein *Dictionary* `buchstaben`, das zu Anfang leer ist und gehen folgendermaßen vor:\n",
    "1. Wir durchlaufen alle Buchstaben des Textes.\n",
    "2. Prüfe, ob der aktuelle Buchstabe als *key* im Dictionary vorkommt\n",
    "    1. Falls er nicht vorkommt, fügen wir den Buchstaben als Schlüssel hinzu und setzen den Wert des Schlüssels auf 1.\n",
    "    2. Falls er vorkommt, erhöhen wir den Wert des Eintrags um 1\n",
    "3. Nachdem alle Buchstaben des Textes verarbeitet sind, durchlaufen wir alle Schlüssel des Dictionaries `buchstaben` und teilen jeden Wert durch die Anzahl der Buchstaben im Text. Beispiel: Wenn der Text 1000 Zeichen hat und der Wert `buchstaben['e']` gleich 100 ist, so setzen wir `buchstaben['e']` auf 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "FxxcglRXHbG2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc4e4d1d25f4ccb7763118899b1a9569",
     "grade": false,
     "grade_id": "cell-e3210bdb55f634d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def letter_frequency(text):\n",
    "    buchstaben = {}\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return buchstaben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8993b649a4fe1f9002e7ef439021a6fb",
     "grade": true,
     "grade_id": "cell-d4732b418a68990d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_freq = letter_frequency(\"pizza\")\n",
    "assert 'z' in test_freq\n",
    "assert 'e' not in test_freq\n",
    "assert test_freq['z']==0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben nun eine Methode `letter_frequency`, mit der wir die relativen Häufigkeiten der Buchstaben eines Textes bestimmen können.\n",
    "Um einen ersten Eindruck von diesen Häufigkeiten zu bekommen, werden wir ein Säulendiagramm erstellen.\n",
    "Dazu verwenden wir die Bibliothek `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "gIE3WSlHSPtF",
    "outputId": "870cc949-d0d6-4268-e397-b90bee8bdf85"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = random_text(1000, 'de')\n",
    "buchstaben = letter_frequency(text)\n",
    "\n",
    "plt.figure(figsize=(30,5)) \n",
    "\n",
    "x = range(len(buchstaben))\n",
    "y = list(buchstaben.values())\n",
    "x_ticks = list(buchstaben.keys())\n",
    "plt.bar(x, y, align='center')\n",
    "plt.xticks(x, x_ticks, rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sieht, sind die Einträge im Dictionary unsortiert.\n",
    "Weder die Schlüssel noch die Werte folgen einer Ordnung.\n",
    "\n",
    "Um die Buchstabenhäufigkeiten aber später vergleichen zu können, wollen wir einen *Vektor* erzeugen, bei dem Buchstaben immer an gleicher Stelle stehen. Z.B. `a` an Index 0, `b` an Index 1, usw.\n",
    "Eine Idee könnte sien, die Schlüssel zu sortieren.\n",
    "Hierbei ist aber Vorsicht geboten, denn es könnt sein, dass ein Buchstabe im Text nicht vorkommt.\n",
    "In dem Fall, hätte der Vektor zu wenige Einträge.\n",
    "\n",
    "Wir verfolgen daher einen anderen Weg.\n",
    "Über eine `for`-Schleife zählen wir alle Buchstaben von *a* bis *z* auf, schauen nach, ob sie im Dictionary enthalten sind und übernehmen den Wert in eine Liste.\n",
    "Ist der Buchstabe nicht enthalten, übernehmen wir den Wert 0.0 in die Liste.\n",
    "\n",
    "Eine Schleife, die alle Buchstaben durchläuft könnte so aussehen\n",
    "```pypthon\n",
    "for i in range(ord('a'), ord('z')+1):\n",
    "    print(chr(i), end=' ')\n",
    "```\n",
    "\n",
    "`ord('a')` liefert den ASCII Code des Zeichens *a*.\n",
    "So kann die Schleife die ASCII Codes von *a* bis *z* durchlaufen.\n",
    "Im Schleifenrumpf erzeugen wir aus dem ASCII Code mit der Typumwnadlung `chr` wieder ein Zeichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwhZ1ngWoKLS",
    "outputId": "9c6ac4c4-b398-460d-86a7-73fba54a1d14"
   },
   "source": [
    "**Aufgabe:** Schreiben Sie eine Funktion `frequency_vector(d)`, die aus einem Dictionary `d` ein Tupel mit 26 Einträgen erzeugt, in denen jeweils die relative Häufigkeit der Buchstaben von  *a* bis *z* im Text steht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "nkQo4k0mRWDH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb07a60136d6177328067a04c7282ed5",
     "grade": false,
     "grade_id": "cell-46b518676b8a892c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def frequency_vector(d):\n",
    "    f = []\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0396aae17a6ca547d881fec4896d1e3a",
     "grade": true,
     "grade_id": "cell-4863565dff2767ea",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_d = {'a': 0.5, 'd': 0.5}\n",
    "test_l = [0.0]*26\n",
    "test_l[0]=0.5\n",
    "test_l[3]=0.5\n",
    "assert frequency_vector(test_d)==tuple(test_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Code-Zelle werden die zuvor entwickelten Funktionen verwendet, um die relativen Häufigkeiten der Buchstaben in den Sprachen *Deutsch*, *Englisch*, *Spanisch* und *Französisch* zu bestimmen.\n",
    "Wir verwenden dazu jeweils 10000 Zeichen aus Wikipedia Artikeln.\n",
    "Die Resultate werden im Dictionary `haeufigkeiten` unter den Schlüsseln `'de'`, `'en'`, `'es'` und `'fr'` abgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOjMsTNGqXvg",
    "outputId": "9a45dd4f-222e-439f-f542-b5ccddf0e008"
   },
   "outputs": [],
   "source": [
    "languages = ['de', 'en', 'es', 'fr']\n",
    "\n",
    "def get_lang_freq(lang):\n",
    "  text = random_text(10000, lang)\n",
    "  buchstaben = letter_frequency(text)\n",
    "  return frequency_vector(buchstaben)\n",
    "\n",
    "haeufigkeiten = {}\n",
    "for l in languages:\n",
    "  haeufigkeiten[l] = get_lang_freq(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun haben wir verschiedene Vektoren, die wir als Maßstab für die einzelnen Sprachen verwenden können.\n",
    "Als Nächstes wollen wir überprüfen, of wir diese Vektoren verwenden können, um für einen neuen Text vorherzusagen, in welcher Sprache er geschrieben ist.\n",
    "\n",
    "Dazu definiert die folgende Code-Zelle die Funktion `get_page_freq`, mit der wir den Inhalt einer speziellen Wikipediaseite herunterladen und die relative Häufigkeit der Buschstaben in dieser Seite berechnen können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnktjcNbs6gB",
    "outputId": "01522105-ddfa-4315-e067-312468d7d470"
   },
   "outputs": [],
   "source": [
    "def get_wiki_page(term, lang='de'): \n",
    "  WIKI = wikipediaapi.Wikipedia(\n",
    "        language=lang,\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    "  )\n",
    "  page = WIKI.page(term)\n",
    "  assert page.exists()\n",
    "  t = page.text\n",
    "  t_cleaned = re.sub('[^a-zA-Z]', '', t)\n",
    "  t_cleaned = t_cleaned.lower()\n",
    "  return t_cleaned\n",
    "\n",
    "def get_page_freq(term, lang='de'):\n",
    "  text = get_wiki_page(term, lang=lang)\n",
    "  buchstaben = letter_frequency(text)\n",
    "  return frequency_vector(buchstaben)\n",
    "\n",
    "mypage = get_page_freq(\"Hochschule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An dieser Stelle haben wir fünf Vektoren, je einen, der die Häufigkeiten der Buchstaben in den Sprachen *Deutsch*, *Englisch*, *Spanisch* und *Französisch* beschreibt sowie einen weiteren, mit den relativen Häufigkeiten der Buchstaben in *unserem* Text.\n",
    "Nun wollen wir ausrechnen, zu welchem der vier Sprach-Vektoren unser Buchstaben-Vektor *am ähnlichsten* ist, bzw. zu welchem Sprach-Vektor er die wenigsten Unterschiede aufweist.\n",
    "\n",
    "Wir werden also die einzelnen Buchstaben-Häufigkeiten in unserem Vektor mit denen im Sprach-Vektor *vergleichen*.\n",
    "Mathematisch gesehen, bilden wir die Differenz der Häufigkeiten aller einzelnen Buchstaben.\n",
    "Kommt z.B. in unserem Text das *e* zu 10% und im Sprach-Vektor zu 8% vor, so ist die Abweichung $0.1-0.08=0.02$ für den Buchstaben *e*.\n",
    "\n",
    "Wenn wir nun alle Abweichungen aufsummieren, kann es zu einem Problem kommen.\n",
    "Manche Differenzen werden positiv, andere negativ sein.\n",
    "Eine einfache Summe wird die negativen und positiven Abweichungen gegeneinander aufrechen.\n",
    "\n",
    "Um dieses Problem zu beheben, gibt es verschiedene Möglichkeiten.\n",
    "Man kann die Absolutwerte der Abweichungen aufsummieren, oder auch deren Quadratwerte.\n",
    "In jedem Fall wird die Summe am Ende durch die Anzahl der Einträge des Vektors geteilt, um den Mittleren Fehler zu berechnen.\n",
    "\n",
    "Verwendet man zum Berechnung die Absolutwerte, nennt man das Maß [*Mittlerer absoluter Fehler*](https://de.wikipedia.org/wiki/Mittlerer_absoluter_Fehler) (oder *mean absolute error*), verwendet man die Fehlerquadrate heißt das Maß [*Mittlerer quadratischer Fehler*](https://de.wikipedia.org/wiki/Mittlere_quadratische_Abweichung) (oder *mean squared error*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** Implementieren Sie die Funktion `mse` zur Berechnung des Mittleren Quadratischen Fehlers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "jBuvWTb0uNn3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de5ab0131c113a18468d37c9105b8e28",
     "grade": false,
     "grade_id": "cell-3dfc34653d980953",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "cd140542-1727-486c-caaa-dff6c55c9ad1"
   },
   "outputs": [],
   "source": [
    "def mse(a,b):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7f85c519aceb38c8aa098e65b0d3079",
     "grade": true,
     "grade_id": "cell-ebdcc724b63e3788",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5]\n",
    "b = [3,2,5,4,5]\n",
    "assert mse(a,b)==1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können wir unsere Vektoren vergleichen und herausfinden, zu welcher Sprache unser Vektor am ähnlichsten ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItgkQgDUv4DQ",
    "outputId": "47cc177e-d140-4277-c44b-a2d9c9fa7678"
   },
   "outputs": [],
   "source": [
    "def get_prop(mypage, languages):\n",
    "  fehler = {}\n",
    "  for l in languages:\n",
    "    fehler[l] = mse(mypage,languages[l])\n",
    "\n",
    "  fehlersumme = sum(fehler.values())\n",
    "\n",
    "  props = {}\n",
    "  for f in fehler:\n",
    "    props[f] = 100-fehler[f]*100/fehlersumme\n",
    "\n",
    "\n",
    "  prop_sum = sum(props.values())\n",
    "\n",
    "  for f in props:\n",
    "    props[f] = props[f]*100/prop_sum\n",
    "\n",
    "  return props\n",
    "\n",
    "p = get_prop(mypage, haeufigkeiten)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SR1mFXq8v1SP"
   },
   "source": [
    "Das Dictionary `p` enthält die berechneten Wahrscheinlichkeiten, mit denen der Text in den jeweiligen Sprachen verfasst ist.\n",
    "Man sollte sehen, dass bei einem deutschen Text, der key `'de'` den höchsten Wert enthält. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie man sieht, ist die Häufigkeit der verschiedenen Buchstaben ein mögliches Vorhersagekriterium, allerdings kein sehr gutes. Die Wahrscheinlichkeiten für Deutsch und Englisch sind i.d.R. nicht sehr verschieden.\n",
    "\n",
    "Um das Verfahren zu verbessern, könnte man statt einzelne Buchstaben ganze Worte betrachten.\n",
    "Oder alternativ dazu, Sequenzen von $n$ aufeinanderfolgenden Buchstaben, den sogenannten [n-Grammen](https://de.wikipedia.org/wiki/N-Gramm).\n",
    "\n",
    "Wenn man einen Text auf n-Gramme untersucht, betrachtet man Folgen von $n$ Buchstaben von jedem Buchstaben aus.\n",
    "In der folgenden Code-Zelle verwenden wir das Wort *Waschmaschine* als Beispiel.\n",
    "Das Wort hat 13 Buchstaben und besitzt damit 11 Trigramme (3-Gramme) von denen eines (das *sch*) doppelt vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wort = 'Waschmaschine'\n",
    "[wort[i:i+3] for i in range(len(wort)-2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe:** \n",
    "1. Generieren Sie einen zufälligen Text mit 2000 Zeichen\n",
    "2. Teilen Sie den Text so auf, dass Sie die einzelnen Worte in einer Liste ablegen. Berechnen Sie die 3-Gramme für alle Worte im Text und speichern Sie die 3-Gramme in einer Liste\n",
    "3. Es sollen nur die 3-Gramme betrachtet werden. D.h, wenn ein Wort weniger als 3 Buchstaben besitzt, nehmen Sie es nicht in die Liste auf\n",
    "4. Geben Sie die Anzahl aller 3-Gramme aus, die in ihrem Text enthalten sind\n",
    "5. Geben Sie die Anzahl aller eindeutigen 3-Gramme aus, d.h. ohne doppelte Vorkommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3457e54c5857b7a8314a7b9f6ad6024b",
     "grade": true,
     "grade_id": "cell-6c176063748f271c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
